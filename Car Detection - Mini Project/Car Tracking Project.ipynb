{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-18T08:12:06.494208Z",
     "start_time": "2021-03-18T08:11:37.976200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.5.1\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "import cv2 as cv2\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "print(cv2.__version__)\n",
    "from os.path import isfile, join\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "backSub = cv2.createBackgroundSubtractorMOG2(detectShadows=False, history=15,varThreshold=50) \n",
    "\n",
    "def getFrame(sec,vidcap):\n",
    "    frame=[]\n",
    "    bk=[]\n",
    "    vidcap.set(cv2.CAP_PROP_POS_MSEC,sec*1000)\n",
    "    hasFrames,image = vidcap.read()\n",
    "    if hasFrames:\n",
    "        frame = backSub.apply(image)\n",
    "        bk = cv2.bitwise_or(image, image, mask=frame)\n",
    "\n",
    "    return hasFrames,frame,image,bk\n",
    "\n",
    "def scale_contour(cnt, scale):\n",
    "    M = cv2.moments(cnt)\n",
    "    cx = int(M['m10']/M['m00'])\n",
    "    cy = int(M['m01']/M['m00'])\n",
    "\n",
    "    cnt_norm = cnt - [cx, cy]\n",
    "    cnt_scaled = cnt_norm * scale\n",
    "    cnt_scaled = cnt_scaled + [cx, cy]\n",
    "    cnt_scaled = cnt_scaled.astype(np.int32)\n",
    "\n",
    "    return cnt_scaled\n",
    "\n",
    "bkimg=[]\n",
    "col_images = []\n",
    "orginal_img=[]\n",
    "face_cascade = cv2.CascadeClassifier('cars.xml')\n",
    "\n",
    "vidcap = cv2.VideoCapture('test_video.mp4')\n",
    "sec = 0\n",
    "frameRate = 0.1\n",
    "count=1\n",
    "success,np_frame,image,bkim = getFrame(sec, vidcap)\n",
    "while success:\n",
    "    col_images.append(np_frame)\n",
    "    orginal_img.append(image)\n",
    "    bkimg.append(bkim)\n",
    "    count = count + 1\n",
    "    sec = sec + frameRate\n",
    "    sec = round(sec, 2)\n",
    "    success,np_frame,image,bkim= getFrame(sec,vidcap)\n",
    "    \n",
    "\n",
    "for i in range(len(orginal_img)-1):\n",
    "    grayA = cv2.cvtColor(bkimg[i], cv2.COLOR_BGR2GRAY)\n",
    "    grayB = cv2.cvtColor(bkimg[i+1], cv2.COLOR_BGR2GRAY)\n",
    "    diff_image = cv2.absdiff(grayB, grayA)\n",
    "    blur = cv2.GaussianBlur(diff_image,(5,5),0)\n",
    "    ret, thresh = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    kernel = np.ones((4,4), np.uint8)\n",
    "    kernel2 = np.ones((2,2),np.uint8)\n",
    "    erosion = cv2.erode(thresh,kernel2,iterations = 1)\n",
    "    closing = cv2.morphologyEx(erosion, cv2.MORPH_CLOSE, kernel,iterations=3)\n",
    "\n",
    "    contours, hierarchy = cv2.findContours(closing.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_TC89_KCOS)\n",
    "\n",
    "    # calculate moments and extract size of contoour disregard small\n",
    "    moment_dict = {}\n",
    "    for index, cnt in enumerate(contours):\n",
    "        moment_dict[index] = cv2.moments(cnt)\n",
    "\n",
    "    obj_properties = {}\n",
    "    for index, obj_moments in moment_dict.items():\n",
    "        if obj_moments['m00'] >2000 and obj_moments['m00'] < 50000:\n",
    "            area = obj_moments['m00']\n",
    "            cx = obj_moments['m10'] / obj_moments['m00']\n",
    "            cy = obj_moments['m01'] / obj_moments['m00']\n",
    "            peri = cv2.arcLength(contours[index], True)\n",
    "            q = (peri/(math.sqrt(area)))\n",
    "            props = {}\n",
    "            props['q'] = q\n",
    "            props['peri'] = peri\n",
    "            props['area'] = area\n",
    "            props['cx'] = cx\n",
    "            props['cy'] = cy\n",
    "            obj_properties[index] = props\n",
    "\n",
    "        all_the_q = [v['q'] for k, v in obj_properties.items()]\n",
    "        min_q = min(all_the_q, default=0)\n",
    "        max_q = max(all_the_q, default=0)\n",
    "        range_q = max_q - min_q\n",
    "\n",
    "    cmap = plt.cm.get_cmap('terrain')\n",
    "    for index, prop in obj_properties.items():\n",
    "        if range_q > 0:\n",
    "            v = (prop['q'] - min_q) / range_q\n",
    "            r, g, b, a = [int(x) for x in cmap(v, bytes=True)]\n",
    "\n",
    "            x,y,w,h = cv2.boundingRect(contours[index])  \n",
    "            cv2.rectangle(orginal_img[i],(x,y),(x+w,y+h),(255,255,255),3)\n",
    "\n",
    "            ctimg= orginal_img[i][y:y+h, x:x+w]\n",
    "\n",
    "    cv2.imshow('video', orginal_img[i])\n",
    "    if cv2.waitKey(33) == 27:\n",
    "        break\n",
    "\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dilater = cv2.dilate(opening, kernel2, iterations=7)\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OPEN CVl",
   "language": "python",
   "name": "virtual_env_name"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
